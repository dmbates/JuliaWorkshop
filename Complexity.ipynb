{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity in fitting Linear Mixed Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear mixed-effects models are increasingly used for the analysis of data from experiments in fields like psychology where several subjects are each exposed to each of several different items.\n",
    "In addition to a response, which here will be assumed to be on a continuous scale, such as a _response time_, a number of experimental conditions are systematically varied during the experiment.\n",
    "In the language of statistical experimental design the latter variables are called _experimental factors_ whereas factors like `Subject` and `Item` are _blocking factors_.\n",
    "That is, these are known sources of variation that usually are not of interest by themselves but still should be accounted for when looking for systematic variation in the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from experiment 2 in [_Kronmueller and Barr (2007)_](https://www.sciencedirect.com/science/article/pii/S0749596X06000581) consist of the response times (ms.) for target selection by 56 participants (undergraduate students) on 32 items (a block of displays) under combinations of 3 two-level experimental factors; `Speaker` (old/new), `Precedent` (break/maintain), and `Load` (Yes/No).\n",
    "\n",
    "These data are available as the `\"kb07\"` dataframe in the [_RePsychLing_ package](https://github.com/dmbates/RePsychLing/) for [__R__](http://www.R-project.org).\n",
    "\n",
    "A copy is also available in the `test/dat.rda` file in the [_MixedModels_ package](https://github.com/dmbates/MixedModels.jl) repository.\n",
    "This file can be loaded into a [__Julia__](https://julialang.org) session using the [_RData_ package](https://github.com/JuliaData/RData.jl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools, DataFrames, Distributions, FreqTables\n",
    "using MixedModels, RData, Statistics, StatsBase, Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>G</th><th>H</th><th>Y</th><th>S</th><th>T</th><th>U</th><th>V</th><th>W</th><th>X</th><th>Z</th></tr><tr><th></th><th>Categorical…</th><th>Categorical…</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>1,790 rows × 10 columns</p><tr><th>1</th><td>30</td><td>1</td><td>2267.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>2</th><td>30</td><td>2</td><td>3856.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>3</th><td>30</td><td>3</td><td>1567.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>4</th><td>30</td><td>4</td><td>1732.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>5</th><td>30</td><td>5</td><td>2660.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>6</th><td>30</td><td>6</td><td>2763.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>7</th><td>30</td><td>7</td><td>3528.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>8</th><td>30</td><td>8</td><td>1741.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>9</th><td>30</td><td>9</td><td>3692.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>10</th><td>30</td><td>10</td><td>1949.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>11</th><td>30</td><td>11</td><td>2189.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>12</th><td>30</td><td>12</td><td>2207.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>13</th><td>30</td><td>13</td><td>2078.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>14</th><td>30</td><td>14</td><td>1901.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>15</th><td>30</td><td>15</td><td>4015.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>16</th><td>30</td><td>16</td><td>1880.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>17</th><td>30</td><td>17</td><td>1444.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>18</th><td>30</td><td>18</td><td>1683.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>19</th><td>30</td><td>19</td><td>2037.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>20</th><td>30</td><td>20</td><td>1168.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>21</th><td>30</td><td>21</td><td>1930.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>22</th><td>30</td><td>22</td><td>1843.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>23</th><td>30</td><td>23</td><td>4969.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>24</th><td>30</td><td>24</td><td>1798.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>25</th><td>30</td><td>25</td><td>2436.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>26</th><td>30</td><td>26</td><td>2018.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>27</th><td>30</td><td>27</td><td>2278.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>28</th><td>30</td><td>28</td><td>1866.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>29</th><td>30</td><td>29</td><td>1743.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>30</th><td>30</td><td>30</td><td>1963.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& G & H & Y & S & T & U & V & W & X & Z\\\\\n",
       "\t\\hline\n",
       "\t& Categorical… & Categorical… & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 30 & 1 & 2267.0 & 1.0 & -1.0 & 1.0 & -1.0 & 1.0 & -1.0 & -1.0 \\\\\n",
       "\t2 & 30 & 2 & 3856.0 & -1.0 & 1.0 & -1.0 & -1.0 & 1.0 & -1.0 & 1.0 \\\\\n",
       "\t3 & 30 & 3 & 1567.0 & -1.0 & -1.0 & -1.0 & 1.0 & 1.0 & 1.0 & -1.0 \\\\\n",
       "\t4 & 30 & 4 & 1732.0 & 1.0 & 1.0 & -1.0 & 1.0 & -1.0 & -1.0 & -1.0 \\\\\n",
       "\t5 & 30 & 5 & 2660.0 & 1.0 & -1.0 & -1.0 & -1.0 & -1.0 & 1.0 & 1.0 \\\\\n",
       "\t6 & 30 & 6 & 2763.0 & -1.0 & 1.0 & 1.0 & -1.0 & -1.0 & 1.0 & -1.0 \\\\\n",
       "\t7 & 30 & 7 & 3528.0 & -1.0 & -1.0 & 1.0 & 1.0 & -1.0 & -1.0 & 1.0 \\\\\n",
       "\t8 & 30 & 8 & 1741.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\\\\n",
       "\t9 & 30 & 9 & 3692.0 & 1.0 & -1.0 & 1.0 & -1.0 & 1.0 & -1.0 & -1.0 \\\\\n",
       "\t10 & 30 & 10 & 1949.0 & -1.0 & 1.0 & -1.0 & -1.0 & 1.0 & -1.0 & 1.0 \\\\\n",
       "\t11 & 30 & 11 & 2189.0 & -1.0 & -1.0 & -1.0 & 1.0 & 1.0 & 1.0 & -1.0 \\\\\n",
       "\t12 & 30 & 12 & 2207.0 & 1.0 & 1.0 & -1.0 & 1.0 & -1.0 & -1.0 & -1.0 \\\\\n",
       "\t13 & 30 & 13 & 2078.0 & 1.0 & -1.0 & -1.0 & -1.0 & -1.0 & 1.0 & 1.0 \\\\\n",
       "\t14 & 30 & 14 & 1901.0 & -1.0 & 1.0 & 1.0 & -1.0 & -1.0 & 1.0 & -1.0 \\\\\n",
       "\t15 & 30 & 15 & 4015.0 & -1.0 & -1.0 & 1.0 & 1.0 & -1.0 & -1.0 & 1.0 \\\\\n",
       "\t16 & 30 & 16 & 1880.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\\\\n",
       "\t17 & 30 & 17 & 1444.0 & 1.0 & -1.0 & 1.0 & -1.0 & 1.0 & -1.0 & -1.0 \\\\\n",
       "\t18 & 30 & 18 & 1683.0 & -1.0 & 1.0 & -1.0 & -1.0 & 1.0 & -1.0 & 1.0 \\\\\n",
       "\t19 & 30 & 19 & 2037.0 & -1.0 & -1.0 & -1.0 & 1.0 & 1.0 & 1.0 & -1.0 \\\\\n",
       "\t20 & 30 & 20 & 1168.0 & 1.0 & 1.0 & -1.0 & 1.0 & -1.0 & -1.0 & -1.0 \\\\\n",
       "\t21 & 30 & 21 & 1930.0 & 1.0 & -1.0 & -1.0 & -1.0 & -1.0 & 1.0 & 1.0 \\\\\n",
       "\t22 & 30 & 22 & 1843.0 & -1.0 & 1.0 & 1.0 & -1.0 & -1.0 & 1.0 & -1.0 \\\\\n",
       "\t23 & 30 & 23 & 4969.0 & -1.0 & -1.0 & 1.0 & 1.0 & -1.0 & -1.0 & 1.0 \\\\\n",
       "\t24 & 30 & 24 & 1798.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\\\\n",
       "\t25 & 30 & 25 & 2436.0 & 1.0 & -1.0 & 1.0 & -1.0 & 1.0 & -1.0 & -1.0 \\\\\n",
       "\t26 & 30 & 26 & 2018.0 & -1.0 & 1.0 & -1.0 & -1.0 & 1.0 & -1.0 & 1.0 \\\\\n",
       "\t27 & 30 & 27 & 2278.0 & -1.0 & -1.0 & -1.0 & 1.0 & 1.0 & 1.0 & -1.0 \\\\\n",
       "\t28 & 30 & 28 & 1866.0 & 1.0 & 1.0 & -1.0 & 1.0 & -1.0 & -1.0 & -1.0 \\\\\n",
       "\t29 & 30 & 29 & 1743.0 & 1.0 & -1.0 & -1.0 & -1.0 & -1.0 & 1.0 & 1.0 \\\\\n",
       "\t30 & 30 & 30 & 1963.0 & -1.0 & 1.0 & 1.0 & -1.0 & -1.0 & 1.0 & -1.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1790×10 DataFrame. Omitted printing of 4 columns\n",
       "│ Row  │ G            │ H            │ Y       │ S       │ T       │ U       │\n",
       "│      │ \u001b[90mCategorical…\u001b[39m │ \u001b[90mCategorical…\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├──────┼──────────────┼──────────────┼─────────┼─────────┼─────────┼─────────┤\n",
       "│ 1    │ 30           │ 1            │ 2267.0  │ 1.0     │ -1.0    │ 1.0     │\n",
       "│ 2    │ 30           │ 2            │ 3856.0  │ -1.0    │ 1.0     │ -1.0    │\n",
       "│ 3    │ 30           │ 3            │ 1567.0  │ -1.0    │ -1.0    │ -1.0    │\n",
       "│ 4    │ 30           │ 4            │ 1732.0  │ 1.0     │ 1.0     │ -1.0    │\n",
       "│ 5    │ 30           │ 5            │ 2660.0  │ 1.0     │ -1.0    │ -1.0    │\n",
       "│ 6    │ 30           │ 6            │ 2763.0  │ -1.0    │ 1.0     │ 1.0     │\n",
       "│ 7    │ 30           │ 7            │ 3528.0  │ -1.0    │ -1.0    │ 1.0     │\n",
       "│ 8    │ 30           │ 8            │ 1741.0  │ 1.0     │ 1.0     │ 1.0     │\n",
       "│ 9    │ 30           │ 9            │ 3692.0  │ 1.0     │ -1.0    │ 1.0     │\n",
       "│ 10   │ 30           │ 10           │ 1949.0  │ -1.0    │ 1.0     │ -1.0    │\n",
       "⋮\n",
       "│ 1780 │ 103          │ 22           │ 1623.0  │ 1.0     │ -1.0    │ -1.0    │\n",
       "│ 1781 │ 103          │ 23           │ 2706.0  │ -1.0    │ 1.0     │ 1.0     │\n",
       "│ 1782 │ 103          │ 24           │ 4281.0  │ -1.0    │ -1.0    │ 1.0     │\n",
       "│ 1783 │ 103          │ 25           │ 2075.0  │ 1.0     │ 1.0     │ 1.0     │\n",
       "│ 1784 │ 103          │ 26           │ 3179.0  │ 1.0     │ -1.0    │ 1.0     │\n",
       "│ 1785 │ 103          │ 27           │ 1216.0  │ -1.0    │ 1.0     │ -1.0    │\n",
       "│ 1786 │ 103          │ 28           │ 2286.0  │ -1.0    │ -1.0    │ -1.0    │\n",
       "│ 1787 │ 103          │ 29           │ 1202.0  │ 1.0     │ 1.0     │ -1.0    │\n",
       "│ 1788 │ 103          │ 30           │ 1581.0  │ 1.0     │ -1.0    │ -1.0    │\n",
       "│ 1789 │ 103          │ 31           │ 1601.0  │ -1.0    │ 1.0     │ 1.0     │\n",
       "│ 1790 │ 103          │ 32           │ 1941.0  │ -1.0    │ -1.0    │ 1.0     │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb07 = load(joinpath(dirname(pathof(MixedModels)), \"..\", \"test\", \"dat.rda\"))[\"kb07\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data frame the names of the columns have been shortened to single characters as\n",
    "- `Y`: response time (ms.)\n",
    "- `G`: subject\n",
    "- `H`: item\n",
    "- `S`: speaker\n",
    "- `T`: precedent\n",
    "- `U`: load\n",
    "\n",
    "The three experimental factors have been converted to $\\pm1$ coding and their two- and three-factor interactions have been created explicitly.\n",
    "For example, `V` is the `S * T` interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Union…</th><th>Nothing</th><th>DataType</th></tr></thead><tbody><p>10 rows × 8 columns</p><tr><th>1</th><td>G</td><td></td><td>30</td><td></td><td>103</td><td>56</td><td></td><td>CategoricalString{UInt8}</td></tr><tr><th>2</th><td>H</td><td></td><td>1</td><td></td><td>32</td><td>32</td><td></td><td>CategoricalString{UInt8}</td></tr><tr><th>3</th><td>Y</td><td>2180.49</td><td>336.0</td><td>1936.5</td><td>5143.65</td><td></td><td></td><td>Float64</td></tr><tr><th>4</th><td>S</td><td>0.0</td><td>-1.0</td><td>0.0</td><td>1.0</td><td></td><td></td><td>Float64</td></tr><tr><th>5</th><td>T</td><td>0.0</td><td>-1.0</td><td>0.0</td><td>1.0</td><td></td><td></td><td>Float64</td></tr><tr><th>6</th><td>U</td><td>0.00111732</td><td>-1.0</td><td>1.0</td><td>1.0</td><td></td><td></td><td>Float64</td></tr><tr><th>7</th><td>V</td><td>0.00111732</td><td>-1.0</td><td>1.0</td><td>1.0</td><td></td><td></td><td>Float64</td></tr><tr><th>8</th><td>W</td><td>0.0</td><td>-1.0</td><td>0.0</td><td>1.0</td><td></td><td></td><td>Float64</td></tr><tr><th>9</th><td>X</td><td>0.0</td><td>-1.0</td><td>0.0</td><td>1.0</td><td></td><td></td><td>Float64</td></tr><tr><th>10</th><td>Z</td><td>-0.00111732</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td></td><td></td><td>Float64</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Union… & Nothing & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & G &  & 30 &  & 103 & 56 &  & CategoricalString\\{UInt8\\} \\\\\n",
       "\t2 & H &  & 1 &  & 32 & 32 &  & CategoricalString\\{UInt8\\} \\\\\n",
       "\t3 & Y & 2180.49 & 336.0 & 1936.5 & 5143.65 &  &  & Float64 \\\\\n",
       "\t4 & S & 0.0 & -1.0 & 0.0 & 1.0 &  &  & Float64 \\\\\n",
       "\t5 & T & 0.0 & -1.0 & 0.0 & 1.0 &  &  & Float64 \\\\\n",
       "\t6 & U & 0.00111732 & -1.0 & 1.0 & 1.0 &  &  & Float64 \\\\\n",
       "\t7 & V & 0.00111732 & -1.0 & 1.0 & 1.0 &  &  & Float64 \\\\\n",
       "\t8 & W & 0.0 & -1.0 & 0.0 & 1.0 &  &  & Float64 \\\\\n",
       "\t9 & X & 0.0 & -1.0 & 0.0 & 1.0 &  &  & Float64 \\\\\n",
       "\t10 & Z & -0.00111732 & -1.0 & -1.0 & 1.0 &  &  & Float64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×8 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ variable │ mean        │ min   │ median │ max     │ nunique │ nmissing │\n",
       "│     │ \u001b[90mSymbol\u001b[39m   │ \u001b[90mUnion…\u001b[39m      │ \u001b[90mAny\u001b[39m   │ \u001b[90mUnion…\u001b[39m │ \u001b[90mAny\u001b[39m     │ \u001b[90mUnion…\u001b[39m  │ \u001b[90mNothing\u001b[39m  │\n",
       "├─────┼──────────┼─────────────┼───────┼────────┼─────────┼─────────┼──────────┤\n",
       "│ 1   │ G        │             │ 30    │        │ 103     │ 56      │          │\n",
       "│ 2   │ H        │             │ 1     │        │ 32      │ 32      │          │\n",
       "│ 3   │ Y        │ 2180.49     │ 336.0 │ 1936.5 │ 5143.65 │         │          │\n",
       "│ 4   │ S        │ 0.0         │ -1.0  │ 0.0    │ 1.0     │         │          │\n",
       "│ 5   │ T        │ 0.0         │ -1.0  │ 0.0    │ 1.0     │         │          │\n",
       "│ 6   │ U        │ 0.00111732  │ -1.0  │ 1.0    │ 1.0     │         │          │\n",
       "│ 7   │ V        │ 0.00111732  │ -1.0  │ 1.0    │ 1.0     │         │          │\n",
       "│ 8   │ W        │ 0.0         │ -1.0  │ 0.0    │ 1.0     │         │          │\n",
       "│ 9   │ X        │ 0.0         │ -1.0  │ 0.0    │ 1.0     │         │          │\n",
       "│ 10  │ Z        │ -0.00111732 │ -1.0  │ -1.0   │ 1.0     │         │          │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(kb07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(kb07.V .== kb07.S .* kb07.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that columns of data frames are extracted as \"properties\" using the dot extractor in Julia, like `kb07.V`.\n",
    "The dot is also used for broadcasting operations over vectors so the operator for multiplying two columns component-wise is \"`.*`\" and an element-by-element equality comparison is written \"`.==`\".)\n",
    "\n",
    "The `G` and `H` factors are crossed but not completely balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56×32 Named Array{Int64,2}\n",
       "G ╲ H │  1   2   3   4   5   6   7   8  …  25  26  27  28  29  30  31  32\n",
       "──────┼──────────────────────────────────────────────────────────────────\n",
       "30    │  1   1   1   1   1   1   1   1  …   1   1   1   1   1   1   1   1\n",
       "31    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "34    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "35    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "36    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "37    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "38    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "39    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "41    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "42    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "43    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "44    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "⋮        ⋮   ⋮   ⋮   ⋮   ⋮   ⋮   ⋮   ⋮  ⋱   ⋮   ⋮   ⋮   ⋮   ⋮   ⋮   ⋮   ⋮\n",
       "89    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "91    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "93    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "94    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "95    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "96    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "97    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "98    │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "100   │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "101   │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "102   │  1   1   1   1   1   1   1   1      1   1   1   1   1   1   1   1\n",
       "103   │  1   1   1   1   1   1   1   1  …   1   1   1   1   1   1   1   1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHtbl = freqtable(kb07, :G, :H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Int64} with 2 entries:\n",
       "  0 => 2\n",
       "  1 => 1790"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countmap(vec(GHtbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the experimental factors vary within subject and within item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple model with main-effects for each of the experimental factors and with random effects for subject and for item is described by the formula `Y ~ 1 + S + T + U + (1|G) + (1|H)`.\n",
    "In the _MixedModels_ package, which uses the formula specifications from the [_StatsModels_ package](https://github.com/JuliaStats/StatsModels.jl), a formula must be wrapped in a call to the `@formula` macro.\n",
    "The model is created as an instance of a `LinearMixedModel` type then fit with a call to the `fit!` generic.\n",
    "\n",
    "(By convention, the names in Julia of _mutating functions_, which modify the value of one or more of their arguments, end in `!` as a warning to the user that arguments, usually just the first argument, can be overwritten with new values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " Y ~ 1 + S + T + U + (1 | G) + (1 | H)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.44157021×10⁴  2.88314042×10⁴  2.88454042×10⁴   2.8883834×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Variance Std.Dev. \n",
       " G         101978.30 319.3404\n",
       " H         131612.90 362.7849\n",
       " Residual  518767.52 720.2552\n",
       " Number of obs: 1790; levels of grouping factors: 56, 32\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error  z value P(>|z|)\n",
       "(Intercept)   2180.72   78.8909  27.6422  <1e-99\n",
       "S            -67.1968   17.0244 -3.94709   <1e-4\n",
       "T            -333.674   17.0244 -19.5998  <1e-84\n",
       "U             78.8989   17.0244  4.63447   <1e-5\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = fit!(LinearMixedModel(@formula(Y ~ 1 + S + T + U + (1|G) + (1|H)), kb07))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first fit of such a model can take several seconds because the Just-In-Time (JIT) compiler must analyze and compile a considerable amount of code.  (All of the code in the _MixedModels_ package is Julia code.)\n",
    "Subsequent fits of this or similar models are much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.304641 seconds (496.90 k allocations: 27.518 MiB, 2.83% gc time)\n"
     ]
    }
   ],
   "source": [
    "const f1 = @formula(Y ~ 1 + S + T + U + (1|G) + (1|H));\n",
    "@time fit!(LinearMixedModel(f1, kb07));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When timing function calls that take less than a few seconds, it is more stable to use the `@benchmark` macro from the [_BenchmarkTools_ package](https://github.com/JuliaCI/BenchmarkTools.jl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  701.09 KiB\n",
       "  allocs estimate:  2414\n",
       "  --------------\n",
       "  minimum time:     1.777 ms (0.00% GC)\n",
       "  median time:      1.816 ms (0.00% GC)\n",
       "  mean time:        2.108 ms (6.01% GC)\n",
       "  maximum time:     84.739 ms (97.33% GC)\n",
       "  --------------\n",
       "  samples:          2368\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark fit!(LinearMixedModel($f1, $kb07))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The use of `$f1` and `$kb07` is an interpolation syntax that has the effect in this macro call of timing only the function execution and not the argument name lookup.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction versus model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `m1` object is created in the call to the constructor function, `LinearMixedModel`, then the parameters are optimized or fit in the call to `fit!`.\n",
    "Usually the process of fitting a model will take longer than creating the numerical representation but for simple models the creation time can be a significant portion of the overall running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  667.63 KiB\n",
       "  allocs estimate:  1117\n",
       "  --------------\n",
       "  minimum time:     652.910 μs (0.00% GC)\n",
       "  median time:      666.951 μs (0.00% GC)\n",
       "  mean time:        738.542 μs (8.46% GC)\n",
       "  maximum time:     3.715 ms (70.62% GC)\n",
       "  --------------\n",
       "  samples:          6737\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearMixedModel($f1, $kb07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  33.38 KiB\n",
       "  allocs estimate:  1296\n",
       "  --------------\n",
       "  minimum time:     1.024 ms (0.00% GC)\n",
       "  median time:      1.045 ms (0.00% GC)\n",
       "  mean time:        1.131 ms (0.67% GC)\n",
       "  maximum time:     17.637 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4410\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark fit!($m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  33.58 KiB\n",
       "  allocs estimate:  1302\n",
       "  --------------\n",
       "  minimum time:     1.052 ms (0.00% GC)\n",
       "  median time:      1.075 ms (0.00% GC)\n",
       "  mean time:        1.169 ms (0.63% GC)\n",
       "  maximum time:     19.542 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4268\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark refit!($m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The `refit!` method allows for specifying a new response vector and reinitializing some of the structure.\n",
    "It is useful for simulations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors affecting the time to optimize the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization process is summarized in the `optsum` property of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Initial parameter vector: [1.0, 1.0]\n",
       "Initial objective value:  28889.20544069451\n",
       "\n",
       "Optimizer (from NLopt):   LN_BOBYQA\n",
       "Lower bounds:             [0.0, 0.0]\n",
       "ftol_rel:                 1.0e-12\n",
       "ftol_abs:                 1.0e-8\n",
       "xtol_rel:                 0.0\n",
       "xtol_abs:                 [1.0e-10, 1.0e-10]\n",
       "initial_step:             [0.75, 0.75]\n",
       "maxfeval:                 -1\n",
       "\n",
       "Function evaluations:     21\n",
       "Final parameter vector:   [0.443371, 0.503689]\n",
       "Final objective value:    28831.404175679785\n",
       "Return code:              FTOL_REACHED\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.optsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model there are two parameters to be optimized because the objective function, negative twice the log-likelihood, can be _profiled_ with respect to all the other parameters.\n",
    "(See section 3 of [_Bates et al. 2015_](https://www.jstatsoft.org/article/view/v067i01) for details.)\n",
    "Both these parameters must be non-negative (they have a lower bound of zero) and both have an initial value of one.\n",
    "After 21 function evaluations an optimum is declared according to the function value tolerance, either $10^{-8}$ in absolute terms or $10^{-12}$ relative to the current value.\n",
    "\n",
    "The optimization itself has a certain amount of setup and summary time but the majority of the time is spent in the evaluation of the objective - the profiled log-likelihood.\n",
    "\n",
    "Each function evaluation is of the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.443371205404996 \n",
       " 0.5036894347196534"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const θ = m1.θ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.42 KiB\n",
       "  allocs estimate:  57\n",
       "  --------------\n",
       "  minimum time:     41.958 μs (0.00% GC)\n",
       "  median time:      45.220 μs (0.00% GC)\n",
       "  mean time:        48.382 μs (0.00% GC)\n",
       "  maximum time:     9.708 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark objective(updateL!(setθ!($m1, $θ)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a bit under 50 microseconds for each of 21 evaluations gives the total function evaluation time of about 1 ms., which is practically all of the time to fit the model.\n",
    "\n",
    "The majority of the time for the function evaluation for this model is in the call to `updateL!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  320 bytes\n",
       "  allocs estimate:  17\n",
       "  --------------\n",
       "  minimum time:     31.557 μs (0.00% GC)\n",
       "  median time:      33.958 μs (0.00% GC)\n",
       "  mean time:        38.019 μs (0.00% GC)\n",
       "  maximum time:     9.700 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark updateL!($m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an operation that updates the lower Cholesky factor (often written as `L`) of a blocked sparse matrix.\n",
    "\n",
    "There are 4 rows and columns of blocks.\n",
    "The first row and column correspond to the random effects for subject, the second to the random effects for item, the third to the fixed-effects parameters and the fourth to the response.\n",
    "Their sizes and types are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1: LinearAlgebra.Diagonal{Float64,Array{Float64,1}} (56, 56) LinearAlgebra.Diagonal{Float64,Array{Float64,1}}\n",
      "2,1: Array{Float64,2} (32, 56) Array{Float64,2}\n",
      "2,2: LinearAlgebra.Diagonal{Float64,Array{Float64,1}} (32, 32) Array{Float64,2}\n",
      "3,1: Array{Float64,2} (4, 56) Array{Float64,2}\n",
      "3,2: Array{Float64,2} (4, 32) Array{Float64,2}\n",
      "3,3: Array{Float64,2} (4, 4) Array{Float64,2}\n",
      "4,1: Array{Float64,2} (1, 56) Array{Float64,2}\n",
      "4,2: Array{Float64,2} (1, 32) Array{Float64,2}\n",
      "4,3: Array{Float64,2} (1, 4) Array{Float64,2}\n",
      "4,4: Array{Float64,2} (1, 1) Array{Float64,2}\n"
     ]
    }
   ],
   "source": [
    "describeblocks(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two lower-triangular blocked matrices: `A` with fixed entries determined by the model and data, and `L` which is updated for each evaluation of the objective function.\n",
    "The type of the `A` block is given before the size and the type of the `L` block is after the size.\n",
    "For scalar random effects, generated by a random-effects term like `(1|G)`, the (1,1) block is always diagonal for both `A` and `L`.\n",
    "Its size is the number of levels of the grouping factor, `G`.\n",
    "\n",
    "Because subject and item are crossed, the (2,1) block of `A` is dense, as is the (2,1) block of `L`.\n",
    "The (2,2) block of `A` is diagonal because, like the (1,1) block, it is generated from a scalar random effects term.\n",
    "However, the (2,2) block of `L` ends up being dense as a result of \"fill-in\" in the sparse Cholesky factorization.\n",
    "All the blocks associated with the fixed-effects or the response are stored as dense matrices but their dimensions are (relatively) small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing the complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, adding more terms to a model will increase the time required to fit the model.\n",
    "However, there is a big difference between adding fixed-effects terms and adding complexity to the random effects.\n",
    "\n",
    "Adding the two- and three-factor interactions to the fixed-effects terms increases the time required to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "const f2 = @formula(Y ~ 1 + S + T + U + V + W + X + Z + (1|G) + (1|H));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " Y ~ 1 + S + T + U + V + W + X + Z + (1 | G) + (1 | H)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.44132195×10⁴  2.88264391×10⁴  2.88484391×10⁴  2.89088288×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Variance   Std.Dev. \n",
       " G         101993.015 319.36345\n",
       " H         131638.811 362.82063\n",
       " Residual  517261.888 719.20921\n",
       " Number of obs: 1790; levels of grouping factors: 56, 32\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error  z value P(>|z|)\n",
       "(Intercept)   2180.66   78.8924   27.641  <1e-99\n",
       "S            -67.1689   16.9997 -3.95119   <1e-4\n",
       "T            -333.702   16.9997 -19.6299  <1e-85\n",
       "U             78.9525   16.9997  4.64436   <1e-5\n",
       "V             22.1173   16.9997  1.30104  0.1932\n",
       "W            -18.7454   16.9997 -1.10269  0.2702\n",
       "X             5.08292   16.9997 0.299001  0.7649\n",
       "Z            -23.9165   16.9997 -1.40688  0.1595\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const m2 = fit!(LinearMixedModel(f2, kb07))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Notice that none of the interactions are statistically significant.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  60.94 KiB\n",
       "  allocs estimate:  2376\n",
       "  --------------\n",
       "  minimum time:     2.119 ms (0.00% GC)\n",
       "  median time:      2.161 ms (0.00% GC)\n",
       "  mean time:        2.309 ms (0.50% GC)\n",
       "  maximum time:     17.728 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2163\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark fit!($m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, in this case, it is because the number of function evaluations to determine the optimum increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Initial parameter vector: [1.0, 1.0]\n",
       "Initial objective value:  28884.061399826605\n",
       "\n",
       "Optimizer (from NLopt):   LN_BOBYQA\n",
       "Lower bounds:             [0.0, 0.0]\n",
       "ftol_rel:                 1.0e-12\n",
       "ftol_abs:                 1.0e-8\n",
       "xtol_rel:                 0.0\n",
       "xtol_abs:                 [1.0e-10, 1.0e-10]\n",
       "initial_step:             [0.75, 0.75]\n",
       "maxfeval:                 -1\n",
       "\n",
       "Function evaluations:     39\n",
       "Final parameter vector:   [0.444048, 0.504472]\n",
       "Final objective value:    28826.439072750934\n",
       "Return code:              FTOL_REACHED\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.optsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time for each objective function evaluation has not increased substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "const θ2 = m2.θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.42 KiB\n",
       "  allocs estimate:  57\n",
       "  --------------\n",
       "  minimum time:     47.349 μs (0.00% GC)\n",
       "  median time:      51.091 μs (0.00% GC)\n",
       "  mean time:        55.579 μs (0.00% GC)\n",
       "  maximum time:     9.753 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark objective(updateL!(setθ!(m2, θ2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing complexity of the random effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way in which the model can be extended is to switch to vector-valued random effects.\n",
    "Sometimes this is described as having _random slopes_, so that a subject not only brings their own shift in the typical response but also their own shift in the change due to, say, `Load` versus `No Load`.\n",
    "Instead of just one, scalar, change associated with each subject there is an entire vector of changes in the coefficients.\n",
    "\n",
    "A model with a random slopes for each of the experimental factors for both subject and item is specified as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "const f3 = @formula(Y ~ 1 + S+T+U+V+W+X+Z + (1+S+T+U|G) + (1+S+T+U|H));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " Y ~ 1 + S + T + U + V + W + X + Z + (1 + S + T + U | G) + (1 + S + T + U | H)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.43221551×10⁴  2.86443102×10⁴  2.87023102×10⁴  2.88615194×10⁴\n",
       "\n",
       "Variance components:\n",
       "             Variance   Std.Dev.    Corr.\n",
       " G          91237.7942 302.055945\n",
       "             1943.2438  44.082239 -0.77\n",
       "             3772.6955  61.422272 -0.58 -0.04\n",
       "             4190.1286  64.731203  0.35 -0.78  0.54\n",
       " H         130618.3194 361.411565\n",
       "             1728.1976  41.571596 -0.43\n",
       "            60908.7918 246.797066 -0.68 -0.37\n",
       "             1892.7740  43.506022  0.31 -0.19 -0.16\n",
       " Residual  444339.3955 666.587875\n",
       " Number of obs: 1790; levels of grouping factors: 56, 32\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error  z value P(>|z|)\n",
       "(Intercept)   2180.51   77.1967  28.2462  <1e-99\n",
       "S            -67.0753   18.3566 -3.65402  0.0003\n",
       "T            -333.796   47.1065 -7.08598  <1e-11\n",
       "U             79.0991   19.5507  4.04585   <1e-4\n",
       "V             22.2639   15.7562  1.41303  0.1576\n",
       "W             -18.839   15.7562 -1.19566  0.2318\n",
       "X             5.17653   15.7562 0.328539  0.7425\n",
       "Z            -24.0632   15.7562 -1.52722  0.1267\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const m3 = fit!(LinearMixedModel(f3, kb07))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several interesting aspects of this model fit.\n",
    "\n",
    "First, the number of parameters optimized directly has increased substantially.\n",
    "What was previously a 2-dimensional optimization has now become 20 dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Initial parameter vector: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
       "Initial objective value:  29309.04765501624\n",
       "\n",
       "Optimizer (from NLopt):   LN_BOBYQA\n",
       "Lower bounds:             [0.0, -Inf, -Inf, -Inf, 0.0, -Inf, -Inf, 0.0, -Inf, 0.0, 0.0, -Inf, -Inf, -Inf, 0.0, -Inf, -Inf, 0.0, -Inf, 0.0]\n",
       "ftol_rel:                 1.0e-12\n",
       "ftol_abs:                 1.0e-8\n",
       "xtol_rel:                 0.0\n",
       "xtol_abs:                 [1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10, 1.0e-10]\n",
       "initial_step:             [0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75]\n",
       "maxfeval:                 -1\n",
       "\n",
       "Function evaluations:     652\n",
       "Final parameter vector:   [0.453137, -0.0511007, -0.0536417, 0.0340426, 0.0419768, -0.0708832, -0.0785956, 0.0242634, 0.0457586, 0.0, 0.542181, -0.0265869, -0.252078, 0.0199587, 0.0564136, -0.271171, -0.00441279, 0.0, -0.0619658, 0.00147087]\n",
       "Final objective value:    28644.31020202708\n",
       "Return code:              FTOL_REACHED\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.optsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the number of function evaluations to convergence has gone from under 40 to over 650.\n",
    "\n",
    "The time required for each function evaluation has also increased considerably,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "const θ3 = m3.θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  29.98 KiB\n",
       "  allocs estimate:  559\n",
       "  --------------\n",
       "  minimum time:     585.824 μs (0.00% GC)\n",
       "  median time:      595.414 μs (0.00% GC)\n",
       "  mean time:        626.143 μs (0.54% GC)\n",
       "  maximum time:     20.788 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          7948\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark objective(updateL!(setθ!($m3, $θ3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resulting in much longer times for model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  19.19 MiB\n",
       "  allocs estimate:  367103\n",
       "  --------------\n",
       "  minimum time:     420.348 ms (0.58% GC)\n",
       "  median time:      425.642 ms (0.57% GC)\n",
       "  mean time:        428.377 ms (0.47% GC)\n",
       "  maximum time:     465.773 ms (0.52% GC)\n",
       "  --------------\n",
       "  samples:          12\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark fit!($m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the estimates of the fixed-effects coefficients and their standard errors are not changed very much except for the standard error of `T` (_Precedent_), which is also the largest coefficient.\n",
    "(Changing from _Break_ to _Maintain_ decreases typical response time by about 667 ms.  The \"effect\" is twice the coefficient because of the $\\pm1$ coding.  See Table 3 in [_Kronmuller and Barr (2007)_](https://www.sciencedirect.com/science/article/pii/S0749596X06000581) or evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>T</th><th>Y_Statistics.mean</th></tr><tr><th></th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>2 rows × 2 columns</p><tr><th>1</th><td>-1.0</td><td>2514.18</td></tr><tr><th>2</th><td>1.0</td><td>1846.8</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& T & Y\\_Statistics.mean\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & -1.0 & 2514.18 \\\\\n",
       "\t2 & 1.0 & 1846.8 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "2×2 DataFrame\n",
       "│ Row │ T       │ Y_Statistics.mean │\n",
       "│     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m           │\n",
       "├─────┼─────────┼───────────────────┤\n",
       "│ 1   │ -1.0    │ 2514.18           │\n",
       "│ 2   │ 1.0     │ 1846.8            │"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by(kb07, :T, :Y => mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore the estimates of the standard deviations of the \"slope\" random effects are much smaller than the those of the intercept random effects except for the `T` coefficient random effect for `H` (_Item_), which suggests that the model could be reduced to `Y ~ 1 + S+T+U+V+W+X+Z + (1|G) + (1+T|H)` or even `Y ~ 1 + S+T+U + (1|G) + (1+T|H)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "const f4 = @formula(Y ~ 1 + S+T+U + (1|G) + (1+T|H));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " Y ~ 1 + S + T + U + (1 | G) + (1 + T | H)\n",
       "     logLik        -2 logLik          AIC             BIC       \n",
       " -1.43356888×10⁴  2.86713775×10⁴  2.86893775×10⁴  2.87387873×10⁴\n",
       "\n",
       "Variance components:\n",
       "            Variance  Std.Dev.   Corr.\n",
       " H         132370.10 363.82702\n",
       "            63784.32 252.55558 -0.69\n",
       " G          89087.40 298.47512\n",
       " Residual  460058.54 678.27615\n",
       " Number of obs: 1790; levels of grouping factors: 32, 56\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error  z value P(>|z|)\n",
       "(Intercept)   2180.62   77.3592  28.1883  <1e-99\n",
       "S            -67.1353   16.0323 -4.18752   <1e-4\n",
       "T            -333.736   47.4373 -7.03531  <1e-11\n",
       "U              78.992   16.0323  4.92707   <1e-6\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const m4 = fit!(LinearMixedModel(f4, kb07))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of comparing models `m3` and `m4` is a likelihood ratio test.\n",
    "\n",
    "The difference in the objective, negative twice the log-likelihood, is similar to the change in the residual sum of squares in a linear model fit.\n",
    "This objective would be called the _deviance_ if there was a way of defining a saturated model but it is not clear what this should be.\n",
    "However, if there was a way to define a deviance then the difference in the deviances would be the same as the differences in these objectives, which is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 27.06734432979283"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(objective.([m3, m4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in the degrees of freedom, in one way of counting, is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Int64,1}:\n",
       " 20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(dof.([m4, m3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "producing a p-value of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13337992341386884"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdf(Chisq(20), first(diff(objective.([m3,m4]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
